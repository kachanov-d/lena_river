{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "bublik",
      "language": "python",
      "name": "bublik"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "forecasting.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "killing-cardiff"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "%run data_preprocessing.ipynb\n",
        "%run create_X_Y.ipynb\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from datetime import datetime, timedelta, date\n",
        "\n"
      ],
      "id": "killing-cardiff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "social-looking"
      },
      "source": [
        "class post_model(hydropost):\n",
        "    \"\"\"\n",
        "    Класс post_model наследует класс hydropost и служит для удобной работы с моделями.\n",
        "    \"\"\"\n",
        "    def __init__(self, loc_id='3012', high_of_measurement=281):\n",
        "        super().__init__(loc_id, high_of_measurement)\n",
        "\n",
        "        \n",
        "    def make_simple_formation(self):\n",
        "        \"\"\"\n",
        "        Метод служит для быстрой предобработки данных по заранее определенному маршруту. После получения \n",
        "        прогноза, прогнозируемая величина должна быть обратно преобразованна в исходные еденицы измерения.\n",
        "        \"\"\"\n",
        "        self.cut_level_nas(will_nas=8)\n",
        "        self.interp_gaps(features=['water_temperature', 'snow_depth', 'ice_thickness'], fillwith=0, between=30)\n",
        "        self.interp_gaps(features=set(self.hydroframe.columns.to_list())-{'min_level' , 'avg_level'},  between=20)\n",
        "        self.diff_timeseries(features=['max_level'], add=True)\n",
        "        self.log_timeseries(features=['max_level'])\n",
        "        self.something_like_mrw(features=['max_level', 'maxairtemperature_mean', 'minairtemperature_mean', 'maxrelativehumidity_mean'])\n",
        "        self.mean_timeseries(features=self.hydroframe.columns, scaling=True)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def make_trains(self, frame=None,               # Фрейм, который следует сплитить. Если None cплитится hydroframe.\n",
        "                    column_to_predict='max_level',  # Целевая переменная.\n",
        "                    split_date='2014-01-01',        # Первая дата разбиения, до- трейн, после- тест.\n",
        "                    split_date_2=None,              # Вторая дата разбиения, если указана, до- тест, после- валидационная.\n",
        "                    day_forward=0,                  # На сколько Y сдвинут относительно X вперед (для XGB моделей).                \n",
        "                    lags=None,                      # Добавляет лаггированые признаки к выборкам до lags дня.\n",
        "                    ret=False,                      # Возвращать выборки или присвоить их атрибутам объекта.\n",
        "                    cut_months=False):              # cut_months={'start':4, 'end':7}  Позволяет вырезать только необходимый временной промежуток по месяцам.\n",
        "        \"\"\"\n",
        "        Метод разбивает hydroframe, или внешний frame на трейновую, тестовую, валидационнцю выборку с возможностью лаггирования признаков,\n",
        "        обрезания месяцев, сдвига Y на day_forward дней вперед для бустинговых моделей. Выборки возвращаются, если ret=True, или присваиваются как атрибуты\n",
        "        объекта.\n",
        "        \"\"\"\n",
        "        \n",
        "        if frame is None:\n",
        "            frame=self.hydroframe \n",
        "        \n",
        "    \n",
        "        train = frame.loc[frame.index <= split_date].copy()\n",
        "        try:\n",
        "            test = frame.loc[(frame.index > split_date) & (frame.index < split_date_2)].copy()\n",
        "        except TypeError:\n",
        "            test = frame.loc[frame.index > split_date].copy()\n",
        "            \n",
        "        if split_date_2 != None:\n",
        "            test2=frame.loc[frame.index > split_date_2].copy()\n",
        "        listoffeatures= frame.columns.to_list()\n",
        "        \n",
        "        x_train=(train[listoffeatures].shift(day_forward)).iloc[(day_forward+1):]\n",
        "        y_train=(train[column_to_predict]).iloc[(day_forward+1):]    \n",
        "        x_test=(test[listoffeatures].shift(day_forward)).iloc[(day_forward+1):]\n",
        "        y_test=(test[column_to_predict]).iloc[(day_forward+1):]\n",
        "        \n",
        "        if split_date_2 != None:\n",
        "            x_test2=(test2[listoffeatures].shift(day_forward)).iloc[(day_forward+1):]\n",
        "            y_test2=(test2[column_to_predict]).iloc[(day_forward+1):]\n",
        "        if (lags is not None) and(lags!=0):\n",
        "            try:\n",
        "                lagged_x_train, lagged_x_test, lagged_x_test2= pd.DataFrame(index=x_train.index),pd.DataFrame(index=x_test.index), pd.DataFrame(index=x_test2.index)\n",
        "            except UnboundLocalError: \n",
        "                lagged_x_train, lagged_x_test=pd.DataFrame(index=x_train.index),pd.DataFrame(index=x_test.index)\n",
        "                \n",
        "            for lag in range(1,lags+1):\n",
        "                lagged_x_train=pd.merge(lagged_x_train, x_train.shift(lag).iloc[(lag+1):].add_prefix(('lag_'+str(lag))+'_'),left_index=True, right_index=True)        \n",
        "                lagged_x_test=pd.merge(lagged_x_test, x_test.shift(lag).iloc[(lag+1):].add_prefix(('lag_'+str(lag))+'_'),left_index=True, right_index=True)\n",
        "                if split_date_2 != None:\n",
        "                    lagged_x_test2=pd.merge(lagged_x_test2, x_test2.shift(lag).iloc[(lag+1):].add_prefix(('lag_'+str(lag))+'_'),left_index=True, right_index=True)\n",
        "            \n",
        "            x_train=pd.merge(x_train, lagged_x_train, left_index=True, right_index=True, how='right')\n",
        "            x_test=pd.merge(x_test, lagged_x_test, left_index=True, right_index=True,how='right')\n",
        "            y_test=y_test.iloc[lags+1:]\n",
        "            y_train=y_train.iloc[lags+1:]\n",
        "            if split_date_2 != None:\n",
        "                x_test2=pd.merge(x_test2, lagged_x_test2, left_index=True, right_index=True,how='right')\n",
        "                y_test2=y_test2.iloc[lags+1:]         \n",
        "        \n",
        "        if cut_months!=False:\n",
        "            if 'x_train' and 'y_train' and 'x_test' and 'y_test' and 'x_test2' and 'y_test2' in locals():\n",
        "                x_train, y_train, x_test, y_test, x_test2, y_test2=x_train.loc[(x_train.index.month >= cut_months['start']) & (x_train.index.month <= cut_months['end'])],\\\n",
        "                                                                   y_train.loc[(y_train.index.month>= cut_months['start']) & (y_train.index.month <= cut_months['end'])],\\\n",
        "                                                                   x_test.loc[(x_test.index.month>= cut_months['start']) & (x_test.index.month <= cut_months['end'])],\\\n",
        "                                                                   y_test.loc[(y_test.index.month>= cut_months['start']) & (y_test.index.month <= cut_months['end'])],\\\n",
        "                                                                   x_test2.loc[(x_test2.index.month>= cut_months['start']) & (x_test2.index.month <= cut_months['end'])],\\\n",
        "                                                                   y_test2.loc[(y_test2.index.month>= cut_months['start']) & (y_test2.index.month <= cut_months['end'])]\n",
        "                \n",
        "            elif  'x_train' and 'y_train' and 'x_test' and 'y_test' in locals():\n",
        "                x_train, y_train, x_test, y_test=x_train.loc[(x_train.index.month>= cut_months['start']) & (x_train.index.month<= cut_months['end'])],\\\n",
        "                                                 y_train.loc[(y_train.index.month>= cut_months['start']) & (y_train.index.month<= cut_months['end'])],\\\n",
        "                                                 x_test.loc[(x_test.index.month>= cut_months['start']) & (x_test.index.month<= cut_months['end'])],\\\n",
        "                                                 y_test.loc[(y_test.index.month>= cut_months['start']) & (y_test.index.month<= cut_months['end'])]                                                        \n",
        "        \n",
        "        if ret==False:\n",
        "            if split_date_2 != None:\n",
        "                self.x_train, self.y_train, self.x_test, self.y_test, self.x_test2, self.y_test2 =x_train, y_train, x_test, y_test,x_test2,y_test2\n",
        "            elif split_date_2 == None:\n",
        "                self.x_train, self.y_train, self.x_test, self.y_test=x_train, y_train, x_test, y_test                \n",
        "        elif ret==True:\n",
        "            if split_date_2 == None:\n",
        "                return  x_train, y_train, x_test, y_test\n",
        "            elif split_date_2 != None:\n",
        "                return x_train, y_train, x_test, y_test,x_test2,y_test2\n",
        "                \n",
        "            \n",
        "\n",
        "    \n",
        "\n",
        "    def make_LSTM_model(self, cuted=False,\n",
        "                        lr=0.001,\n",
        "                        lag=14,\n",
        "                        LSTM_units=34,             #Число элементов на LSTM-слое\n",
        "                        batch_size=128,\n",
        "                        dense_layers={1:50, 2: 50} #Число скрытых слоев и количество нейронов на каждом из слоев\n",
        "                       ):\n",
        "        \"\"\"\n",
        "        Метод обучает первую LSTM-модель (без разделения скрытых слоев) с заданными гиперпараметрами на трейновых, тестовых выборках, хранимых в атрибутах объекта.\n",
        "        Готовая модель доступна по self.LSTM_model\n",
        "        \"\"\"\n",
        "        self.LSTM_samples={}\n",
        "        if cuted==False:\n",
        "\n",
        "            \n",
        "            x_train_np=self.x_train.reset_index(drop=True)\n",
        "            x_train_np=self.x_train.to_numpy()\n",
        "            x_test_np=self.x_test.reset_index(drop=True)\n",
        "            x_test_np=self.x_test.to_numpy()\n",
        "            x_test2_np=self.x_test2.reset_index(drop=True)\n",
        "            x_test2_np=self.x_test2.to_numpy()\n",
        "\n",
        "            self.LSTM_samples['Xtrain'],self.LSTM_samples['Ytrain']=create_X_Y(ts=x_train_np, lag=lag, n_ahead=7, target_index=0)  \n",
        "            self.LSTM_samples['Xval'],self.LSTM_samples['Yval']=create_X_Y(ts=x_test_np, lag=lag, n_ahead=7, target_index=0)      \n",
        "            self.LSTM_samples['Xtest'],self.LSTM_samples['Ytest']=create_X_Y(ts=x_test2_np, lag=lag, n_ahead=7, target_index=0)\n",
        "\n",
        "        elif cuted==True:\n",
        "            self.LSTM_samples['Xtrain'],\\\n",
        "            self.LSTM_samples['Ytrain'],\\\n",
        "            self.LSTM_samples['Xval'],\\\n",
        "            self.LSTM_samples['Yval'],\\\n",
        "            self.LSTM_samples['Xtest'],\\\n",
        "            self.LSTM_samples['Ytest']=create_X_Y_cuted(self.x_train,\n",
        "                                                        self.y_train,\n",
        "                                                        self.x_test,\n",
        "                                                        self.y_test,\n",
        "                                                        self.x_test2,\n",
        "                                                        self.y_test2, lag=lag)\n",
        "            \n",
        "            \n",
        "        n_steps=self.LSTM_samples['Xtrain'].shape[1]\n",
        "        n_features=self.LSTM_samples['Xtrain'].shape[2]\n",
        "\n",
        "        model = Sequential() \n",
        "        model.add(LSTM(units=LSTM_units, activation='tanh', return_sequences=False, input_shape=(n_steps, n_features )))\n",
        "        for num in dense_layers:\n",
        "            name = 'layer_dense_'+ str(num)\n",
        "            model.add(Dense(dense_layers[num], activation='tanh', name=name))\n",
        "\n",
        "            \n",
        "        model.add(Dense(7,activation='tanh')) \n",
        "        model.compile(optimizer=Adam(learning_rate=lr), loss=MeanSquaredError()) \n",
        "    \n",
        "        def trainCallback():\n",
        "            return EarlyStopping(monitor='val_loss', patience=5, min_delta=0.00001, verbose=0)\n",
        "        \n",
        "        model.fit(x=self.LSTM_samples['Xtrain'], \n",
        "                        y=self.LSTM_samples['Ytrain'],\n",
        "                        epochs=1000, \n",
        "                        validation_data=(self.LSTM_samples['Xval'],self.LSTM_samples['Yval']), \n",
        "                        shuffle=False,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[trainCallback()])\n",
        "        self.LSTM_model=model\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    def make_week_XGB_stack(self, \n",
        "                            cut_months=False,               \n",
        "                            column_to_predict='max_level',  #Целевая переменная \n",
        "                            split_date='2014-01-01',        #Дата разбиения на трейновую и тестовую выборки\n",
        "                            n_estimators=1000,\n",
        "                            max_depth=6,\n",
        "                            eta=0.1372,\n",
        "                            subsample=0.9521413041539605,\n",
        "                            colsample_bytree=1.0,\n",
        "                            colsample_bylevel=0.72291,\n",
        "                            min_child_weight= 0.24052,\n",
        "                            reg_lambda=0.03559,\n",
        "                            alpha=0.61582,\n",
        "                            gamma=0\n",
        "                           ):\n",
        "        \n",
        "        \"\"\"\n",
        "        Метод формирует выборки, обучает семь XGB моделей с заданными гиперпараметрами, сформированных по step-forward подходу, по одной для каждого дня прогноза.\n",
        "        \"\"\"\n",
        "        if hasattr(self, 'week_XGB')==False:\n",
        "            self.week_XGB = dict.fromkeys(['XGBmod_day_forward_'+ str(i) for i in range(1,8)])\n",
        "        for num, model in enumerate(self.week_XGB):\n",
        "            x_train, y_train, x_test, y_test=self.make_trains(column_to_predict=column_to_predict, split_date=split_date, day_forward=num+1, ret=True, cut_months=cut_months)\n",
        "            self.week_XGB[model]=xgb.XGBRegressor( n_estimators=n_estimators, max_depth=max_depth, eta=eta, subsample=subsample, colsample_bytree=colsample_bytree, colsample_bylevel=colsample_bylevel, min_child_weight=min_child_weight,reg_lambda=reg_lambda,alpha=alpha,gamma=gamma)  \n",
        "            self.week_XGB[model].fit(x_train, y_train,\n",
        "            eval_set=[(x_train, y_train), (x_test, y_test)],\n",
        "            early_stopping_rounds=50,\n",
        "            verbose=False)   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "    def make_models_prediction(self, \n",
        "                               actual_date='2017-12-20', \n",
        "                               column_to_predict='max_level',\n",
        "                               LSTM_lag=13 ): #Лаг обязан быть тем же, с каким обучали модель\n",
        "        \"\"\"\n",
        "        Метод позволяет формировать прогнозы XGB и LSTM моделей на актуальный день (если данные актуальны),\n",
        "        или какой-либо день в прошлом, исходя из исторических данных. Возвращает словарь с прогнозами XGB,\n",
        "        LSTM моделей и фактический уровень воды на дни предсказаний.\n",
        "        \"\"\"\n",
        "\n",
        "        split_date=str(date.fromisoformat(actual_date)-timedelta(days=LSTM_lag+1))\n",
        "        split_date_2=str(date.fromisoformat(actual_date)+timedelta(days=1))\n",
        "        _, _, x_test, check,_,_=self.make_trains(split_date=split_date, split_date_2=split_date_2, day_forward=0,  column_to_predict=column_to_predict, ret=True)\n",
        "        \n",
        "        XGB_pred=np.array([])\n",
        "        for model in self.week_XGB:\n",
        "            XGB_pred=np.append(XGB_pred, float(self.week_XGB[model].predict(x_test.iloc[-1:] )))\n",
        "        \n",
        "        LSTM_input=x_test.reset_index(drop=True).to_numpy()\n",
        "        nlag=LSTM_input.shape[0]\n",
        "        nft=LSTM_input.shape[1]\n",
        "        LSTM_pred=self.LSTM_model.predict(x_test.reset_index(drop=True).to_numpy().reshape(1, nlag, nft))\n",
        "        LSTM_pred=np.array([float(x) for x in LSTM_pred])\n",
        "        measured=self.hydroframe.loc[(self.hydroframe.index > actual_date) & (self.hydroframe.index <= str(date.fromisoformat(actual_date)+timedelta(days=7)))][column_to_predict].reset_index(drop=True).to_numpy()\n",
        "        return {'XGB':XGB_pred, 'LSTM':LSTM_pred, 'measured':measured} \n",
        "        \n",
        "        \n",
        "    \n",
        "    def make_stackframe(self, dateinterval={'start':'2010-01-01','end':'2016-01-01'}, \n",
        "                        LSTM_lag=13, #Лаг обязан быит таким же, с каким обучали модель \n",
        "                        ret=False):\n",
        "        \"\"\"\n",
        "        Метод формирует выборку из предсказаний XGB, LSTM моделей  на временном интервале \n",
        "        для обучения ансамблирующих моделей. Готовый фрейм, помеченный днями дальности прогноза присваивается как \n",
        "        атрибут, либо возвращается. \n",
        "        \"\"\"\n",
        "        stackframe= self.hydroframe.loc[(self.hydroframe.index > dateinterval['start']) & (self.hydroframe.index < dateinterval['end'])].copy()\n",
        "        for day in stackframe.index.strftime(\"%Y-%m-%d\"):\n",
        "            preddict=self.make_models_prediction(actual_date=day, LSTM_lag=LSTM_lag)\n",
        "            for i in range(0,7):\n",
        "                stackframe.loc[str(date.fromisoformat(day)+timedelta(i+1)), [str('XGB_'+str(i+1)+'_dayf')]] =float(preddict[\"XGB\"][i])\n",
        "                stackframe.loc[str(date.fromisoformat(day)+timedelta(i+1)), [str('LSTM_'+str(i+1)+'_dayf')]]=float(preddict[\"LSTM\"][i])\n",
        "        returnedframe=pd.DataFrame()\n",
        "        for day in stackframe.index:\n",
        "            for i in range(1,8):\n",
        "                row=stackframe.loc[[day],['max_level','LSTM_'+str(i)+'_dayf', 'XGB_'+str(i)+'_dayf']]\n",
        "                row.rename(columns={'LSTM_'+str(i)+'_dayf': 'LSTM', 'XGB_'+str(i)+'_dayf': 'XGB'}, inplace=True)\n",
        "                row['dayf']=i\n",
        "                returnedframe=pd.concat([returnedframe,row])\n",
        "                returnedframe.dropna(inplace=True)\n",
        "        if ret==False:\n",
        "            self.stackframe=returnedframe\n",
        "        elif ret==True:\n",
        "            return returnedframe\n",
        "\n",
        "        \n",
        "        \n",
        "    \n",
        "    def make_stackmodel(self, \n",
        "                        column_to_predict='max_level',\n",
        "                        model='ridge'):  #Так же доступны XGB, tree, lasso\n",
        "        \"\"\"\n",
        "        Метод разворачивает признаки предсказаний XGB, LSTM моделей для семи дней в \n",
        "        пространство нескоррелированных признаков большей размерности с методом Kernel PCA, обучает на полученных метапризнаках один из выбранных базовых алгоритмов.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.kpca_stack={}\n",
        "        self.stackmodel={}\n",
        "        for day in range(1,8):\n",
        "            frame=self.stackframe.loc[self.stackframe['dayf']==day].drop(columns=['dayf'])\n",
        "            #KERNEL PCA вот тут\n",
        "            self.kpca_stack['dayf_'+str(day)] = KernelPCA( kernel='linear') #rbf\n",
        "            decomposed = pd.concat([pd.DataFrame(self.kpca_stack['dayf_'+str(day)].fit_transform(frame.drop(columns=column_to_predict)), index=frame.index), frame[column_to_predict]], axis=1)\n",
        "               \n",
        "\n",
        "            if model=='ridge':\n",
        "                self.stackmodel['dayf_'+str(day)]=RidgeCV(cv=50)\n",
        "                self.stackmodel['dayf_'+str(day)].fit(X=decomposed.drop(columns='max_level'), y=decomposed['max_level'])\n",
        "            elif model=='lasso':\n",
        "                self.stackmodel['dayf_'+str(day)] = LassoCV(cv=50)\n",
        "                self.stackmodel['dayf_'+str(day)].fit(X=decomposed.drop(columns='max_level'), y=decomposed['max_level'])\n",
        "            \n",
        "            elif model=='tree':\n",
        "                self.stackmodel['dayf_'+str(day)]=DecisionTreeRegressor()\n",
        "                self.stackmodel['dayf_'+str(day)].fit(X=decomposed.drop(columns='max_level'), y=decomposed['max_level'])\n",
        "                \n",
        "            elif model=='XGB':\n",
        "                train, test =train_test_split(decomposed, test_size=0.3, random_state=42)   \n",
        "                trains={'x_train':train.drop(columns=[column_to_predict]),\n",
        "                    'y_train':train[column_to_predict],\n",
        "                    'x_test':test.drop(columns=[column_to_predict]),\n",
        "                    'y_test':test[column_to_predict]}\n",
        "                                 \n",
        "                self.stackmodel['dayf_'+str(day)]= xgb.XGBRegressor()\n",
        "                self.stackmodel['dayf_'+str(day)].fit(trains['x_train'], trains['y_train'],\n",
        "                                                eval_set=[(trains['x_train'], trains['y_train']), (trains['x_test'], trains['y_test'])],\n",
        "                                                early_stopping_rounds=10,\n",
        "                                                verbose=False) \n",
        "            \n",
        "\n",
        "\n",
        "    def make_stack_prediction(self, actual_date='2017-12-20', column_to_predict='max_level', LSTM_lag=13):\n",
        "        \"\"\"\n",
        "        Метод возвращает прогноз ансамбля моделей для соответствующего актуального дня.\n",
        "        \"\"\"\n",
        "        m_prediction=self.make_models_prediction( actual_date=actual_date,column_to_predict=column_to_predict, LSTM_lag=LSTM_lag)\n",
        "        \n",
        "        frame=pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in m_prediction.items() ])) #позволяет избежать ошибки разных длин \n",
        "        frame.index=pd.date_range(start=str(date.fromisoformat(actual_date)+timedelta(days=1)), end=str(date.fromisoformat(actual_date)+timedelta(days=7)))\n",
        "        stack_prediction=np.array([])\n",
        "        for day in range(1,8):\n",
        "            transformed=self.kpca_stack['dayf_'+str(day)].transform(frame.iloc[[day-1]].drop(columns='measured'))\n",
        "            stack_prediction=np.append(stack_prediction, self.stackmodel['dayf_'+str(day)].predict(transformed))\n",
        "        frame['stack_pred']=stack_prediction\n",
        "        \n",
        "        for col in frame.columns:\n",
        "            frame[col]=self.mean_timeseries(inverse=frame[col], target='max_level') \n",
        "            frame[col]=self.something_like_mrw(inv=frame[col], target='max_level' )\n",
        "            frame[col]=np.exp(frame[col])\n",
        "        return frame \n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "    def make_LSTM2_model(self, cuted=True, lr=0.00122, lag=14, LSTM_units=34, dense_small=10, dense_small1=10, batch_size=128):\n",
        "        \"\"\"\n",
        "        Вторая LSTM-модель - модель, архитектура которой дала лучшие результаты прогнозирования на недельном интервале\n",
        "        \"\"\" \n",
        "        self.LSTM_samples={}\n",
        "        if cuted==False:\n",
        "\n",
        "            \n",
        "            x_train_np=self.x_train.reset_index(drop=True)\n",
        "            x_train_np=self.x_train.to_numpy()\n",
        "            x_test_np=self.x_test.reset_index(drop=True)\n",
        "            x_test_np=self.x_test.to_numpy()\n",
        "            x_test2_np=self.x_test2.reset_index(drop=True)\n",
        "            x_test2_np=self.x_test2.to_numpy()\n",
        "\n",
        "            self.LSTM_samples['Xtrain'],self.LSTM_samples['Ytrain']=create_X_Y(ts=x_train_np, lag=lag, n_ahead=7, target_index=0) #Обучающий набор \n",
        "            self.LSTM_samples['Xval'],self.LSTM_samples['Yval']=create_X_Y(ts=x_test_np, lag=lag, n_ahead=7, target_index=0)      #Валидационный набор\n",
        "            self.LSTM_samples['Xtest'],self.LSTM_samples['Ytest']=create_X_Y(ts=x_test2_np, lag=lag, n_ahead=7, target_index=0)\n",
        "\n",
        "        elif cuted==True:\n",
        "            self.LSTM_samples['Xtrain'],\\\n",
        "            self.LSTM_samples['Ytrain'],\\\n",
        "            self.LSTM_samples['Xval'],\\\n",
        "            self.LSTM_samples['Yval'],\\\n",
        "            self.LSTM_samples['Xtest'],\\\n",
        "            self.LSTM_samples['Ytest']=create_X_Y_cuted(self.x_train,\n",
        "                                                        self.y_train,\n",
        "                                                        self.x_test,\n",
        "                                                        self.y_test,\n",
        "                                                        self.x_test2,\n",
        "                                                        self.y_test2, lag=lag)\n",
        "            \n",
        "            \n",
        "        n_steps=self.LSTM_samples['Xtrain'].shape[1]\n",
        "        n_features=self.LSTM_samples['Xtrain'].shape[2]\n",
        "        \n",
        "        inputs = tensorflow.keras.layers.Input(shape=(n_steps, n_features ))\n",
        "        lstm_big = LSTM(units=LSTM_units, activation='tanh', return_sequences=False)(inputs)\n",
        "        \n",
        "        \n",
        "        dense_small_1=Dense(dense_small, activation='tanh')(lstm_big)\n",
        "        dense_small_2=Dense(dense_small, activation='tanh')(lstm_big)\n",
        "        dense_small_3=Dense(dense_small, activation='tanh')(lstm_big)\n",
        "        dense_small_4=Dense(dense_small, activation='tanh')(lstm_big)\n",
        "        dense_small_5=Dense(dense_small, activation='tanh')(lstm_big)\n",
        "        dense_small_6=Dense(dense_small, activation='tanh')(lstm_big)\n",
        "        dense_small_7=Dense(dense_small, activation='tanh')(lstm_big)\n",
        "        \n",
        "        drop_1=Dropout(0.5, seed=1)(dense_small_1)\n",
        "        drop_2=Dropout(0.5, seed=1)(dense_small_2)\n",
        "        drop_3=Dropout(0.5, seed=1)(dense_small_3)\n",
        "        drop_4=Dropout(0.5, seed=1)(dense_small_4)\n",
        "        drop_5=Dropout(0.5, seed=1)(dense_small_5)\n",
        "        drop_6=Dropout(0.5, seed=1)(dense_small_6)\n",
        "        drop_7=Dropout(0.5, seed=1)(dense_small_7)\n",
        "        \n",
        "        \n",
        "        dense_small1_1=Dense(dense_small1, activation='tanh')(dense_small_1)\n",
        "        dense_small1_2=Dense(dense_small1, activation='tanh')(dense_small_2)\n",
        "        dense_small1_3=Dense(dense_small1, activation='tanh')(dense_small_3)\n",
        "        dense_small1_4=Dense(dense_small1, activation='tanh')(dense_small_4)\n",
        "        dense_small1_5=Dense(dense_small1, activation='tanh')(dense_small_5)\n",
        "        dense_small1_6=Dense(dense_small1, activation='tanh')(dense_small_6)\n",
        "        dense_small1_7=Dense(dense_small1, activation='tanh')(dense_small_7)\n",
        "        \n",
        "        \n",
        "        drop1_1=Dropout(0.5, seed=1)(dense_small1_1)\n",
        "        drop1_2=Dropout(0.5, seed=1)(dense_small1_2)\n",
        "        drop1_3=Dropout(0.5, seed=1)(dense_small1_3)\n",
        "        drop1_4=Dropout(0.5, seed=1)(dense_small1_4)\n",
        "        drop1_5=Dropout(0.5, seed=1)(dense_small1_5)\n",
        "        drop1_6=Dropout(0.5, seed=1)(dense_small1_6)\n",
        "        drop1_7=Dropout(0.5, seed=1)(dense_small1_7)\n",
        "        \n",
        "        \n",
        "        out_1=Dense(1)(drop1_1) #(dense_small1_1)\n",
        "        out_2=Dense(1)(drop1_2)\n",
        "        out_3=Dense(1)(drop1_3)\n",
        "        out_4=Dense(1)(drop1_4)\n",
        "        out_5=Dense(1)(drop1_5)\n",
        "        out_6=Dense(1)(drop1_6)\n",
        "        out_7=Dense(1)(drop1_7)\n",
        "        \n",
        "        \n",
        "\n",
        "        model = tensorflow.keras.Model(inputs=inputs, outputs=[out_1,out_2,out_3,out_4,out_5,out_6,out_7])\n",
        "        model.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\")\n",
        "        model.summary()\n",
        "        \n",
        "        \n",
        "        model.compile(optimizer=Adam(learning_rate=lr), loss=MeanSquaredError()) \n",
        "            \n",
        "        def trainCallback():\n",
        "            return EarlyStopping(monitor='val_loss', patience=10, min_delta=0.00001, verbose=0)\n",
        "        \n",
        "        self.LSTM_history=model.fit(x=self.LSTM_samples['Xtrain'], \n",
        "                        y=self.LSTM_samples['Ytrain'],\n",
        "                        epochs=1000, \n",
        "                        validation_data=(self.LSTM_samples['Xval'],self.LSTM_samples['Yval']), \n",
        "                        shuffle=False,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[trainCallback()])\n",
        "        self.LSTM_model=model \n",
        "        \n",
        "        \n"
      ],
      "id": "social-looking",
      "execution_count": null,
      "outputs": []
    }
  ]
}